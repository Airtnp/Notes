# Intro to Database Systems

[Fall2018](https://15445.courses.cs.cmu.edu/fall2018/schedule.html)



## Course Intro & Relational Model

* A DBMS is software that allows applications to store and analyze information in a database
* ![1566376714297](D:\OneDrive\Pictures\Typora\1566376714297.png)
* Flat file :x:
* Relational Model
  * 1970, by Ted Codd
  * Store database in simple data structure
  * Access data through high-level language
  * Physical storage left up to implementation
* Data Model
  * A **data model** is collection of concepts for describing the data in a database
  * A **schema** is a description of a particular collection of data, using a given data model
  * DBMS
    * Relational
  * NoSQL
    * Key/Value
    * Graph
    * Document
    * Column-family
  * Machine Learning
    * Array / Matrix
  * Obsolete
    * Hierarchical
    * Network
* Relational Model
  * Structure: The definition of relations and their
    contents
  * Integrity: Ensure the database’s contents satisfy constraints
  * Manipulation: How to access and modify a database’s contents
  * Relation:  unordered set that contain the relationship of attributes that represent entities
  * Tuple:  a set of attribute values (also known as its domain) in the relation
  * Primary Key: uniquely identifies a single tuple
  * Foreign Key: specifies that an attribute from one relation has to map to a tuple in another relation
* Data Manipulation Language (DML)
  * Procedural (RA): → The query specifies the (high-level) strategy the DBMS should use to find the desired result
  * Non-procedural (RC): The query specifies only what data is wanted and not how to find it
* Relational Algebra
  * Select $\sigma_{\text{predicate}}(R)$
    * `SELECT * FROM R WHERE A AND B`
  * Project $\pi_{A1, \cdots, A_n}(R)$
    * `SELECT A1, An FROM R WHERE ...`
  * Union $\cup$
    * `(SELECT ...) UNION (SELECT ...)`
  * Intersection $\cap$
    * `(SELECT ...) INTERSECT (SELECT ...)`
  * Difference $-$
    * `(SELECT ...) EXCEPT (SELECT ...)` (MySQL has no `EXCEPT`)
  * Product $\times$
    * `SELECT * FROM R CROSS JOIN S` / `SELECT * FROM R, S`
  * Join $\bowtie$
    * `SELECT * FROM R NATURAL JOIN S`
  * Extra operators
    * ![1566375743008](D:\OneDrive\Pictures\Typora\1566375743008.png)



## Advanced SQL

* ![1566375853421](D:\OneDrive\Pictures\Typora\1566375853421.png)

* DML: Data Manipulation Language

* DDL: Data Definition Language

* DCL: Data Control Language

* Aggregates

  * `AVG/MIN/MAX/SUM/COUNT([DISTINCT] col/1/*)`
  * `GROUP BY`: project tuples into subsets to calculate aggregates
    * Non-aggregated values in SELECT output clause must appear in GROUP BY clause.
  * `HAVING`: like `WHERE` for `GROUP BY`

* String operators

  * `LIKE`: `%` matches any substring, `_` matches any one character
  * `SUBSTRING(name, 0, 5)`, `UPPER(s)`
  * concat string
    * SQL-92: `s || t`
    * MSSQL: `s + t`
    * MySQL: `CONCAT(s, t)`

* DATE/TIME

* Output redirection

  * `SELECT ... INTO`
  * `CREATE TABLE Name (SELECT ...)`
  * `INSERT INTO Table (SELECT ...)`

* Output control

  * `ORDER BY <column*> [ASC|DESC]`
  * `LIMIT <count> [offset]`

* Nested query

  * `ALL/= ANY/IN/[NOT] EXISTS(SELECT ...)`

* Window function

  * `SELECT ... FUNC-NAME(...) OVER (...) FROM ...`
  * like aggregation but tuples are not grouped into a single output tuples
  * `FUNC-NAME`: aggregate function + `ROW_NUMBER()` + `RANK()`
  * `OVER (...)`
    * `PARTITON BY`: group
    * `ORDER BY`: sort

* CTE (Common Table Expression)

  * `WITH cteName [(output cols, ...)] AS (SELECT ...)         SELECT * FROM cteName`

  * bind output columns to names

  * ```sql
    WITH RECURSIVE cteSource (counter) AS (
        (SELECT 1)
        UNION ALL
        (SELECT counter + 1 FROM cteSource
        	WHERE counter < 10)
    )
    SELECT * FROM cteSource
    ```



## Database Storage

* Storage hierarchy
  * ![1566378414684](D:\OneDrive\Pictures\Typora\1566378414684.png)
  * ![1566378426417](D:\OneDrive\Pictures\Typora\1566378426417.png)
* OS `mmap` => uncontrollable
  * ![1566378495965](D:\OneDrive\Pictures\Typora\1566378495965.png)
* File Storage
  * storage manager
    * track data r/w to pages
    * track available space
  * page: fixed size block of data (1 - 16KB, unlike hardware/OS)
    * unique identifier
  * heap file: an unordered collection of pages where tuples that are stored in random order
    * Get/Delete page
    * iterate over all pages
    * metadata
    * linked list
      * ![1566378658599](D:\OneDrive\Pictures\Typora\1566378658599.png)
    * page directory
      * ![1566378668788](D:\OneDrive\Pictures\Typora\1566378668788.png)
* Page Layout
  * header -> metadata
    * page size / checksum / DBMS version / transaction visibility / compression information
    * self-contained?
  * tuple-oriented
    * slotted pages
      * ![1566378784405](D:\OneDrive\Pictures\Typora\1566378784405.png)
  * log-structured
    * log records
    * ![1566378806004](D:\OneDrive\Pictures\Typora\1566378806004.png)
    * build index for jumping
    * periodically compact the log [[Check: HDFS]]
      * ![1566378870814](D:\OneDrive\Pictures\Typora\1566378870814.png)
* Tuple Layout
  * header -> metadata
    * visibility info (concurrecy control) / BitMap (for NULL)
  * denormalized: pre-join related tuples -> store together (like COW)
  * record ids: page_id + offset/slot
* Data Representation
  * ![1566395497962](D:\OneDrive\Pictures\Typora\1566395497962.png)
  * ![1566395997689](D:\OneDrive\Pictures\Typora\1566395997689.png)
  * Size > 1 Page => overflow page 
    * Postgres: TOAST > 2KB
    * MySQL: Overflow > 1/2 size of page
  * External file => `BLOB`
    * Oracle: BFILE data type
    * Microsoft: FILESTREAM data type
    * no durability protection
    * no transaction protection
* System Catalogs
  * metadata
    * tables/columns/indexes/views
    * users/permissions
    * internal statistics
  * `INFORMATION_SCHEMA`
    * ![1566397156863](D:\OneDrive\Pictures\Typora\1566397156863.png)
    * ![1566397163033](D:\OneDrive\Pictures\Typora\1566397163033.png)
* OLTP: On-Line Transaction Processing
  * read/update small amount of data
* OLAP: On-Line Analytical Processing
  * complex read large portions of database
* Data Storage Model
  * N-ary Storage Model (NSM)
    * all attributes for a single tuple contiguously in a page
    * Advantages
      * fast inserts/updates/deletes
      * good for querying entire tuple
    * Disadvantages
      * not good for scanning large portion of data for a subset of the attributes
  * Decomposition Storage Model (DSM)
    * stores the values of a single attribute for all tuples contiguously in a page
    * Good for subset OLAP
    * Tuple identification
      * Fixed-length Offset
      * Embedded Tuple Ids
    * Advantages
      * reduce amount of wasted I/O
      * better query processing & data compression
    * Disadvantages
      * slow for NSM (tuple splitting/stitching)



## Buffer Pools

* Spatial Control
  * where to write pages on disk
  * physically close
* Temporal Control
  * when to read/write to disk
  * minimize number of stalls
* Buffer Pool
  * pool (frame)
    * multiple instance / per-database / per-page
  * page table: page id -> buffer pool frames (in-memory)
    * dirty flag / pin / reference counter
    * page directory: page id -> page locations (persistent)
  * pre-fetching: prefetch pages based on query plan (sequential / index scan)
  * scan sharing: reuse data retrieved from storage or operator computations
    * multiple queries to attach to a single cursor (share intermediate results)
    * If a query starts a scan and if there one already doing this, then the DBMS will attach to the second query's cursor. The  DBMS keeps track of where the second query joined with the first so that it can finish the scan when it reaches the end of the data structure.
  * buffer pool bypass (light scans): The sequential scan operator will not store fetched pages in the buffer pool to avoid overhead
  * OS page cache: use direct I/O (`O_DIRECT`)
  * Replacement policies
    * LRU, Clock (Second choice) → sequential flooding pollutes the buffer pool
    * LRU-K: use last K reference as timestamps to compute intervals between subsequent accesses and estimate next time accessed.
    * Localization: choose which pages to evict on a per txn/query basis.
      * Postgres: small ring buffer private to the query
    * Priority hints
  * Background writing: evict dirty pages
  * Allocation policies
    * Global: all active txns
    * Local: allocate frames to a specific txn, support sharing pages
  * ![1566399780784](D:\OneDrive\Pictures\Typora\1566399780784.png)
* ![1566399131109](D:\OneDrive\Pictures\Typora\1566399131109.png)



## Hash Tables

* hash function
  * ![1566402450338](D:\OneDrive\Pictures\Typora\1566402450338.png)
* hash schemes
  * static
    * linear probe: resovle collisions by linearly searching for the next free slot
    * robin hood: steals slots from rich keys to poor keys
      * Each key tracks the number of positions they are from where its optimal position in the table
      * On insert, a key takes the slot of another key if the first key is farther away from its optimal position than the second key.
    * cuckoo hashing: use multiple hash tables with different hash functions
      * On insert, check every table and pick anyone that has a free slot
      * If no table has a free slot, evict the element from one of them and then re-hash it find a new location
      * If we find a cycle, then we can rebuild the entire hash tables with new hash functions
  * dynamic
    * extensible hashing
      * ![1566402812942](D:\OneDrive\Pictures\Typora\1566402812942.png)
    * linear hashing
      * ![1566402832605](D:\OneDrive\Pictures\Typora\1566402832605.png)
  * non-unique keys
    * separate linked list
    * redundant keys



## Tree Index

* B-Tree family
  * B-Tree / B+Tree / B-link Tree / B* Tree
* B+ Tree
  * M-way search tree
  * perfectly balanced (every leaf at same depth)
  * $M/2 - 1 \le \text{#keys} \le M - 1$
  * inner node with $k$ keys has $k+1$ non-null children
  * B-Tree store values in leaf
  * Design choice
    * Node size: slower disk, larger node size
    * Merge threshold: delay half full
    * Variable length key
      * pointers
      * variable length nodes
      * key map
    * Non unique indexes
      * duplicate keys
      * value lists
    * Intra-node search
      * Linear
      * BInary
      * Interpolation: apprximate location based on distribution
  * Optimization
    * Prefix compression: Instead of storing the entire key each time, extract common prefix and store only unique suffix for each key
    * Suffix truncation: Store a minimum prefix that is needed to correctly route probes into the index
    * Bulk insert:  Rebuilding -> First sort the keys and then build the index from the bottom up
    * Pointer swizzling: raw pointer to pinned pages in buffer pool instead of page ids
* Leaf Node values
  * record id → locations
  * tuple data
* Additional index
  * implicit index: automatically create an index to enforce integrity constraints
    * primary keys, unique constraints
    * [not for foreign key, but...](https://www.sqlskills.com/blogs/kimberly/when-did-sql-server-stop-putting-indexes-on-foreign-key-columns/)
  * partial index: create an index on a subset of the entire table
    * `CREATE INDEX idx_foo ON foo (a, b) WHERE c = 'xxx'`
  * covering index: if all of the fields needed to process the query are available in an index, no need to retrieve the tuple
  * index include columns: embed additional columns in indexes to support index-only queries
    * `CREATE INDEX idx_foo ON foo (a, b) INCLUDE (c)`
  * functional/expression index
    * `CREATE INDEX idx_user_login ON users WHERE EXTRACT(dow FROM login) = 2;`
* Skip list: dynamic order-preserving index
  * ![1566442120251](D:\OneDrive\Pictures\Typora\1566442120251.png)
  * ![1566442130834](D:\OneDrive\Pictures\Typora\1566442130834.png)
  * delete: logically remove index, physically remove key when no other thread holding [[Check: hazard pointer?]]
  * Advantage
    * less memory than B+ tree if no reverse pointer
    * insertions/deletions do not require rebalancing
  * Disadvantage
    * not disk/cache friendly (no locality of reference)
    * reverse search is not trivial
* Radix tree: compact trie
  * height depends on length of keys
  * no require rebalancing
  * path to leaf node -> key
  * requires binary comparable keys

* R-Tree
* Quad-Tree
* KD-Tree



## Index Concurrency Control

* A concurrency control protocol is the method that the DBMS uses to ensure "correct" results for concurrent operations on a shared object.
  * logical correctness: correct data
  * physical correctness: sound internal representation
* ![1566443435646](D:\OneDrive\Pictures\Typora\1566443435646.png)
* ![1566443714718](D:\OneDrive\Pictures\Typora\1566443714718.png)
* B+ Tree concurrency control
  * latch crabbing/coupling
    * get latch for parent, get latch for child, release latch if safe
    * safe node: not split/merge when update
      * not full (on insertion)
      * more than half-full (on deletion)
    * Search: start at root and go down; repeatedly
      * acquire `R` latch on child, then unlatch parent
    * Insert/Delete: start at root and go down; obtain `W` latch as needed
      * once child is latched, check if child safe, release all latch on ancestors
  * better latching
    * assume leaf node safe, use read latches and crabbing to reach it and verify it's safe
    * not safe, do previous using write latches
    * Insert/Delete
      * set latches as if for search
      * get to leaf and set `W` latch on leaf
      * if leaf is not safe, release all latches, restart thread using previous protocol
  * leaf node scan
    * no-wait mode, failed to lock then abort
  * delayed parent updates
    * B-link Tree: when a leaf node overflows, delay updating its parent node
    * update parent node the next time take a write latch on it



## Query Processing

* Processing model: how system executes a query plan

  * iterator (volcano/pipeline) model: every operator implements a `next` function (top-down)
    * ![1566444809820](D:\OneDrive\Pictures\Typora\1566444809820.png)
    * output control
    * for general purpose
  * materialization model: each operator processing its input all at once and then emits its output all at once (bottom-up)
    * push down hints to avoid scanning all
    * ![1566445347113](D:\OneDrive\Pictures\Typora\1566445347113.png)
    * for OLTP
  * vectorization model: like iterator but emits a batch (top-down)
    * ![1566445426980](D:\OneDrive\Pictures\Typora\1566445426980.png)
    * for OLAP, use vectorized (SIMD) instructions

* Access methods: how DBMS access data stored in a table

  * sequential scan

    * ```
      for page in table.pages:
          for t in page.tuples:
      	    if evalPred(t):
          		// Do Something!
      ```

    * optimizations

      * prefetching / parallelization / buffer pool bypass
      * zone maps: pre-computed aggregates for the attribute values in the page
        * ![1566446467830](D:\OneDrive\Pictures\Typora\1566446467830.png)
      * late materialization: delay stitching together tuples until the upper parts of the query plan (only record intermediate ids)
        * ![1566446517103](D:\OneDrive\Pictures\Typora\1566446517103.png)
      * heap clustering: tuples are sorted in the heap's pages using the order specified by a clustering index
        * ![1566446565391](D:\OneDrive\Pictures\Typora\1566446565391.png)

  * index scan

    * page sort

  * multi-index (Bitmap) scan

    * compute sets of record ids using each matching index
    * combine these sets based on the query's predicates
    * retrieve the records and apply any remaining terms

* expression evaluation: `WHERE` clause

  * ![1566446756250](D:\OneDrive\Pictures\Typora\1566446756250.png)



## Sorting & Aggregations

* External Merge sort
  * sorting phase: sort small chunks of data that fit in main-memory and write-back the sorted data to a file on disk
  * merge phase: combine sorted sub-files into a single larger file
  * Pass #0: use B buffer pages to produce [N / B] sorted runs of size B
  * Pass #1: merge B-1 runs
  * \# of pass = $1 + \lceil \log_{B - 1} \lceil N / B \rceil \rceil$
* Aggregation
  * sorting
  * hashing (`DISTINCT`, `GROUP BY`)  [[Check: Grace Hash, Bloom Filter]]
    * partition phase: use $h_1$ to split tuples into partitions
    * rehash phase: read into memory and build in-memory hash table on $h_2$, go each each bucket of this hash table to bring together matching tuples



## Join Algorithm

* Nested Loop Join
  * simple: $|R| + ||R|| |S|$
  * block: $|R| + \lceil |R| / (B - 2) \rceil * |S|$
  * index: $|R| + ||R|| index(C)$
* Sort-Merge Join
  * external merge sort
  * step through in parallel and emit matching tuples
  * $2|R| \log |R| + 2|S| \log |S| + M + N$
* Hash Join
  * build, then probe
  * hash table values -> full tuple / tuple identifier
  * $3(|R| + |S|)$
* ![1566448378885](D:\OneDrive\Pictures\Typora\1566448378885.png)



## Query Optimization

* heuristics/rules
* cost-based search
* ![1566455841425](D:\OneDrive\Pictures\Typora\1566455841425.png)
* query rewriting
  * selections: perform filters as early as possible
    * $\sigma_{p_1 \wedge \cdots \wedge p_n} (R) = \sigma_{p_1}(\cdots \sigma_{p_n}(R))$
  * projections: perform early to create smaller tuples and reduce intermediate results
  * impossible / unnecessary predicates
  * join projections, ignoring projections, merge predicates
* cost analyze
  * ![1566456065961](D:\OneDrive\Pictures\Typora\1566456065961.png)
  * $N_R$: # of tuples in $R$
  * $V(A, R)$: # of distinct values for attribute $A$
  * $SC(A, R)$: selection cardinality = $N_R / V(A, R)$ (assume data uniformity)
  * $sel$: selectivity of a predicate $P$ is the fraction of tuples that qualify
* left-deep join trees
  * dynamic programming
  * ![1566463649715](D:\OneDrive\Pictures\Typora\1566463649715.png)
  * enumerate relational ordering (eliminate cross product plans)
  * enumerate join algorithm choices



## Parallel Execution

* ![1566464142068](D:\OneDrive\Pictures\Typora\1566464142068.png)
* process model: how the DBMS is architectured to support concurrent requests from a multi-user application
  * worker: executing tasks
  * process per worker: every worker is a separate OS process
  * process pool: a worker uses any process that is free in a pool
  * thread per worker: single process with multiple workers threads (own scheduling)
* Intra-query parallelism
  * intra-operator (horizontal): Operators are decomposed into independent instances that perform the same function on different subsets of data
    * ![1566464359865](D:\OneDrive\Pictures\Typora\1566464359865.png)
  * inter-operator (vertical/pipelined): Operations are overlapped in order to pipeline data from one stage to the next without materialization.
    * mostly used in stream processing systems
* I/O parallelism: Split the DBMS installation across multiple storage devices.
  * multi-disk: storage appliance / RAID (OS / hardware)
  * database partitioning
    * vertical partitioning: Store a table’s attributes in a separate location (e.g., file, disk volume).
    * horizontal partitioning: Divide the tuples of a table up into disjoint segments based on some partitioning key



## Embedded Database Logic

* user-defined function (UDF):  a function written by the application developer that extends
  the system's functionality beyond its built-in operations. (read-only computation within a query)

  * `scalars -> Union[scalars, tables]`

  * ```sql
    CREATE FUNCTION get_foo(int)
    				RETURNS foo AS $$
    	SELECT * FROM foo WHERE foo.id = $1;
    $$ LANGUAGE SQL;
    ```

  * ![1566464873944](D:\OneDrive\Pictures\Typora\1566464873944.png)

  * ```plsql
    CREATE OR REPLACE FUNCTION get_foo(int)
    					RETURNS SETOF foo AS $$
    	BEGIN
    		RETURN QUERY SELECT * FROM foo
            						WHERE foo.id = $1;
    	END;
    $$ LANGUAGE plpgsql;
    
    CREATE OR REPLACE FUNCTION sum_foo(i int)
    					RETURNS int AS $$
        DECLARE foo_rec RECORD;
        DECLARE out INT;
        BEGIN
            out := 0;
            FOR foo_rec IN SELECT id FROM foo
            				WHERE id > i LOOP
    	        out := out + foo_rec.id;
            END LOOP;
            RETURN out;
        END;
    $$ LANGUAGE plpgsql;
    ```

* stored procedure: a self-contained function that performs more complex logic inside of the
  DBMS. (independent of a query)

  * many input/output parameters
  * can modify the database table/structures

* trigger

  * ```sql
    CREATE OR REPLACE FUNCTION log_foo_updates()
    					RETURNS trigger AS $$
        BEGIN
            IF NEW.val <> OLD.val THEN
                INSERT INTO foo_audit
                			(foo_id, orig_val, cdate)
                VALUES (OLD.id, OLD.val, NOW());
            END IF;
            RETURN NEW;
        END;
    $$ LANGUAGE plpgsql;
    
    CREATE TRIGGER foo_updates
    	BEFORE UPDATE ON foo FOR EACH ROW
    EXECUTE PROCEDURE log_foo_updates();
    ```

  * ![1566465143782](D:\OneDrive\Pictures\Typora\1566465143782.png)

* change notification:  like a trigger except that the DBMS sends a message to an external entity
  that something notable has happened in the database.

  * `LISTEN` + `NOTIFY`

  * ```sql
    CREATE OR REPLACE FUNCTION notify_foo_updates()
    					RETURNS trigger AS $$
        DECLARE notification JSON;
        BEGIN
            notification = row_to_json(NEW);
            PERFORM pg_notify('foo_update',
    					        notification::text);
            RETURN NEW;
        END;
    $$ LANGUAGE plpgsql;
    
    CREATE TRIGGER foo_notify
    	AFTER INSERT ON foo_audit FOR EACH ROW
    	EXECUTE PROCEDURE notify_foo_updates();
    ```

* complex types

  * attribute splitting: Store each primitive element in the complex type as its own attribute in the table.

  * application serialization: `JSONB`

  * user-defined (structured) type: a special data type that is defined by the application developer that the DBMS can stored natively

    * ```sql
      CREATE TYPE coordinates AS OBJECT (
          x INT NOT NULL,
          y INT NOT NULL,
          label VARCHAR(32) NOT NULL
      ); 
      ```

* views: "virtual" table containing the output from a `SELECT` query

  * ```sql
    CREATE VIEW cs_students AS
    	SELECT sid, name, login
            FROM student
            WHERE login LIKE '%@cs';
    ```

  * dynamic results are only materialized when needed

  * updating view: only contains one base table, not contain grouping, distinction, union, aggregation

  * `CREATE MATERIALIZED VIEW`: automatically updated when underlying table changes



## Concurrency Control Theory

* transaction: the execution of a sequence of one or more operations (e.g., SQL queries) on a
  shared database to perform some higher-level function.

  * basic unit of change

  * `BEGIN`, `COMMIT/ABORT`

* database: a fixed set of named data objects

* transaction: a sequence of r/w operations

* ACID

  * Atomicity: All actions in the txn happen, or none happen
    * logging: log all actions so it can undo the actions of aborted transaction
    * shadow paging: copies of pages and txns make changes to copies
  * Consistency: If each txn is consistent and the DB starts consistent, then it ends up consistent [[Check: perservation in type theory]]

  * Isolation: Execution of one txn is isolated from that of other txns.
    * concurrency control protocol
      * pessimistic: Don’t let problems arise in the first place
      * optimistic: Assume conflicts are rare, deal with them after they happen
    * serializability
      * serial schedule: A schedule that does not interleave the actions of different transactions
      * equivalent schedules: For any database state, the effect of executing the first schedule is identical to the effect of executing the second schedule
      * serializable schedule: A schedule that is equivalent to some serial execution of
        the transactions
    * conflict serializability
      * RW, WW, WR conflcit
      * conflict equivalent: two schedules involve same actions of the same transactions and every pair of conflicting actions is ordered the same way
      * conflict serializable: conflict equivalent to some serial schedule
      * -> acyclic precedence graph
    * view serializability
      * ![1566466387827](D:\OneDrive\Pictures\Typora\1566466387827.png)
  * Durability: If a txn commits, its effects persist.
    * logging / shadow paging



## Two Phase Locking (2PL)

* Lock types
  
  * ![1566467761632](D:\OneDrive\Pictures\Typora\1566467761632.png)
  
* two phase locking (2PL): determine serializablity order of conflicting operations at runtime (pessimistic)
  * growing phase: each txn requests the lock that it needs from the DBMS's lock manager
  * shrinking phase: txn is allowed to only release locks that it previously acquired, cannot acquire new locks
  * -> conflict serializability (acyclic precedence graph)
  * -> cascading aborts (dirty reads due to aborted txns)
    * strict 2PL: release all locks at the end of txn
    * solve cascading aborts. aborted txns can be undone by just restoring original values of modified tuples
    * ![1566484629953](D:\OneDrive\Pictures\Typora\1566484629953.png)
  * -> deadlock
    * detection: waits-for graph to keep track of what locks each txn is waiting to acquire ([[Check lockdeps]]), periodically check cycle
    * handling: select a victim txn to rollback, then restart or abort
      * by age, by progress, by # of locked items, by # of txns required to rollback, # of restart times
      * rollback length: completely / minimally
    * prevention: older timestamp = higher priority
      * wait-die: old waits for young.
      * wound-wait: young waits for old
      * ![1566484823187](D:\OneDrive\Pictures\Typora\1566484823187.png)
  
* Lock hierarchy

  * intention lock: allows a higher level node to be locked in shared or exclusive mode without having to check all descendent nodes

    * intention-shared (IS): indicates explicit locking at a lower level with shared locks
    * intention-exclusive (IX): indicates locking at lower levle with exclusive or shared locks
    * Shared+Intention-exclusive (SIX): The subtree rooted by that node is locked explicitly in shared mode and explicit locking is being done at a lower level with exclusive-mode locks.
    * ![1566485268077](D:\OneDrive\Pictures\Typora\1566485268077.png)
    * ![1566488928261](D:\OneDrive\Pictures\Typora\1566488928261.png)
    * To get S or IS lock on a node, the txn must hold at least IS on parent node.
    * To get X, IX, or SIX on a node, must hold at least IX on parent node

  * lock escalation: dynamically ask coarser-grained locks when too many low level locks acquired

  * lock table: explicitly locks a table

    * ```sql
      LOCK TABLE <table> IN <mode> MODE; -- postgres/db2/oracle, SHARE/EXCLUSIVE
      SELECT 1 FROM <table> WITH (TABLOCK, <mode>) -- mssql
      LOCK TABLE <table> <mode>; -- mysql, READ/WRITE
      ```

    * `SELECT .. FOR UPDATE -- FOR SHARE (postgres) / LOCK IN SHARE MODE (mysql)`

      * select & exclusive lock
      * used for converting snapshot read -> current read, mvcc -> next-key lock, repeatable read -> serializable
        * [快照读/当前读](cnblogs.com/cat-and-water/p/6427612.html)



## Timestamp Ordering Concurrency Control

* Timestamp ordering (T/O): determine serializability order of txns before execution (optimistic)

  * $TS(T_i)$ < $TS(T_j)$: execution schedule is equivalent to a serial schedule where $T_i$ appears before $T_j$
  * timestamp allocation: unique fixed timestamp that is monotically increasing
    * system clock / logical counter / hybrid
  * $W-TS(X)$: write timestamp on $X$
  * $R - TS(X)$: read timestamp on $X$
  * basic read
    * If $TS(T_i) < W-TS(X)$, violates timestamp order of $T_i$ w.r.t. writer of $X$, abort $T_i$, restart it with same TS [[Note: I believe this is not correct, should be newer TS]]
    * Else allow $T_i$ to read $X$, update $R-TS(X) = max(R-TS(X), TS(T_i))$, make a local copy of $X$ to ensure repeatable reads
  * basic write
    * If $TS(T_i) < R-TS(X) \text{ or } TS(T_i) < W-TS(X)$, abort and restart $T_i$
    * Else allow $T_i$ to write $X$, update $W-TS(X)$, make a local copy of $X$ to ensure repeatable reads
  * Thomas write rule
    * If $W-TS(X) > TS(T_i) \ge R_TS(X)$, ignore the write and allow the txn to continue (through violates the timestamp order of $T_i$)
  * -> conflict serializable (if no TWR), could starvation
  * -> not recoverable
    * Recoverable: if txns commit only after all txns whose changes they read, commit. Otherwise, the DBMS cannot guarantee that txns read data that will be restored after recovering from a crash
  * performance issues
    * copying data to txn's workspace
    * long running txns get starved

* Optimistic concurrency control

  * DBMS creates a private workspace for each txn
    * read copied into workspace, modifications applied to workspace
    * commit -> workspace writes to see conflicts
    * Read phase: Track the read/write sets of txns and store their writes in a private workspace.
    * Validation phase: When a txn commits, check whether it conflicts with other txns
      * serial valiation: $T_i$ checks other txns for RW and WW conflicts and makes sure that all conflicts go one way (from older txns to younger txns)
        * maintain global view of all active txns
        * record read/write set while txns are running and write into private workspace
        * execute Validation & Write phase inside a protected critical section
      * $TS(T_i) < TS(T_j)$ → one of 3
        * $T_i$ completes all three phases before $T_j$ begins.
        * $T_i$ completes before $T_j$ starts its Write phase & $T_i$ does not write to any object read by $T_j$. → WriteSet($T_i$) ∩ ReadSet($T_j$) = Ø
        * $T_i$ completes its Read phase before $T_j$ completes its Read phase & $T_i$ does not write to any object that is either read or written by $T_j$
          * WriteSet($T_i$) ∩ ReadSet($T_j$) = Ø
          * WriteSet($T_i$) ∩ WriteSet($T_j$) = Ø
    * Write phase: If validation succeeds, apply private changes to database, otherwise abort and restart the txn
  * performance
    * overhead for copying data locally
    * validation/write phase
    * abort wateful since they occur after a txn already executed
    * commits need latch to see whether there are conflicts

* Partition-based T/O

  * horizonal partition: split the database up in disjoint subsets (shards)
  * use timestamps to order txns for serial execution at each partition, only check for conflicts betwen txns that are running in the same partition
  * lock per partition (queue), read need every lock, write locked in place (separate in-memory buffer for aborts)

* Dynamic databases: apart from reading/updating, insertions & deletions...

  * phantom read
  * predication/index locking: `status='lit'`, lock index page, or lock to every page/table itself
  * repeating scans: re-execute every scan again when the txn commits and check whether it gets the same result

* weaker levels of isolation

  * isolation levels

    * serializable: No phantoms, all reads repeatable, no dirty reads

      * obtain all locks first + index locks ([[Check gap lock/next-key lock]]) + strict 2PL

    * repeatable reads: phantoms

      * obtain all locks first + strict 2PL / MV-OCC

    * read committed: phantoms + unrepeatable reads

      * obtain all locks first + non-strict 2PL + S locks released immediately after using

    * read uncommitted: phantoms + unrepeatable reads + dirty reads

      * obtains all W locks first + non-strict 2PL

    * ![1566492867628](D:\OneDrive\Pictures\Typora\1566492867628.png)

    * ```sql
      SET TRANSACTION ISOLATION LEVEL <isolation-level>;
      BEGIN TRANSACTION ISOLATION LEVEL <isolation-level>;
      ```

    * ![1566493028929](D:\OneDrive\Pictures\Typora\1566493028929.png)

    * access mode: hint to DBMS that txns will modify

      * ```sql
        SET TRANSACTION <access-mode>; -- READ WRITE / READ ONLY
        BEGIN TRANSACTION <access-mode>;
        ```

* ![image-20191218221149725](D:\OneDrive\Pictures\Typora\image-20191218221149725.png)

## Multi-Version Concurrency Control

* Multi-Version Concurrency Control (MVCC): DBMS maintains multiple physical versions of a singal logical object
  * read-only txns read a consistent snapshot without acquiring locks (timestamp)
  * time-traval queries
  * Concurrency Control protocol
    * Timestamp ordering: Assign txns timestamps that determine serial order
    * Optimistic Concurrency Control: read/validation.write, private workspace for new versions
    * Two-Phase Locking: txns acquire lock on physical version before reading/writing
  * Version Storage: use tuples' pointer field to create a version chain per logical tuple
    * Append-Only storage: New versions are appended to the same table space
      * ![1566526127923](D:\OneDrive\Pictures\Typora\1566526127923.png)
    * Time-Travel Storage: Old versions are copied to separate table space
      * ![1566526206210](D:\OneDrive\Pictures\Typora\1566526206210.png)
    * Delta Storage: The original values of the modified attributes are copied into a separate delta record space
      * ![1566526219235](D:\OneDrive\Pictures\Typora\1566526219235.png)
    * Version Chain ordering: Oldest-2-Newest (O2N, lookup->traverse) / Newest-2-Oldest (N2O, update index)
  * Garbage Collection: remove reclaimable physical versions over time
    * Tuple-level: Find old versions by examining tuples directly
      * Background Vacuuming: Separate thread(s) periodically scan the table and look for reclaimable versions
      * Cooperative Cleaning: Worker threads identify reclaimable versions as they
        traverse version chain. Only works with O2N.
    * Transaction-level: Txns keep track of their old versions so the DBMS does not have to scan tuples to determine visibility
  * Secondary Indexes
    * Logical pointer: Use a fixed identifier per tuple that does not change
    * Physical pointer: Use the physical address to the version chain head
  * ![1566526487035](D:\OneDrive\Pictures\Typora\1566526487035.png)
    * Postgres: MV-SSI
    * [OCC vs. MVCC](https://www.zhihu.com/question/60278698)



## Logging Scheme

* Recovery algorithm: techniques to ensure database consistency, transaction atomicity, and durability despite failures
* Failure classification
  * Transaction failures
    * Logical errors: Transaction cannot complete due to some internal error condition (e.g., integrity constraint violation)
    * Internal state errors: DBMS must terminate an active transaction due to an error condition (e.g., deadlock)
  * System failure
    * Software failure: Problem with the DBMS implementation (e.g., uncaught divide-by-zero exception)
    * Hardware failure: The computer hosting the DBMS crashes (e.g., power plug gets pulled) (fail-stop: non-volatile storage should not corrupted on crash)
  * Storage media failure
    * Non-repairable hardware failure: head crash or disk failure
* Steal policy: Whether the DBMS allows an uncommitted txn to overwrite the most recent committed value of an object in non-volatile storage
* Force policy: Whether the DBMS requires that all updates made by a txn are reflected on non-volatile storage before the txn is allowed to commit
* Shadow paging: Maintain two separate copies of the database (master, shadow)
  * NO-STEAL + FORCE
  * ![1566529312398](D:\OneDrive\Pictures\Typora\1566529312398.png)
  * Undo: remove shadow pages, leave master and DB root pointer alone
  * Redo: not needed
  * overhead: copying entire page table (or path) + commit + GC
* Write-Ahead Log (WAL): Record the changes made to the database in a log file (stable storage) before the change is made
  * STEAL + NO-FORCE
  * `<BEGIN>` TxnId, ObjectId, Before Value (UNDO), After Value (REDO), `<COMMIT>`
  * txn commit -> write log back to disk (or batch multiple logs)
  * Logging scheme
    * physical logging: Record the changes made to a specific location in the database (less data)
    * logical logging: Record the high-level operations executed by txns (fast recovery)
    * physiological logging: hybrid
      * ![1566529623585](D:\OneDrive\Pictures\Typora\1566529623585.png)
  * checkpoints
  * undo uncommitted txns + redo comitted txns



## Database Recovery

* Algorithms for Recovery and Isolation Exploiting Semantics (ARIES)
  * Write-Ahead Logging (STEAL + NO-FORCE)
  * Repeating History During Redo
  * Logging Changes During Undo
  * log sequence number (LSN): every log record includes a globally unique id
    * ![1566530270701](D:\OneDrive\Pictures\Typora\1566530270701.png)
  * `pageLSN` <= `flushedLSN`
  * `prevLSN` for aborting
  * compensation log record (CLR): describes the actions taken to undo the actions of a previous update record. `undoNext`
    * ![1566531934566](D:\OneDrive\Pictures\Typora\1566531934566.png)
  * COMMIT
    * write `COMMIT` log
    * flush log till `COMMIT` to disk
    * commit succeeded -> write `TXN-END` (no need for flushed immediately)
  * ABORT
    * write `ABORT` log
    * play back updates in reverse order, write `CLR` & restore old value
    * write `TXN-END`
  * Fuzzy checkpoint: checkpointing & allowing other txns to run
    * Active Transaction Table (ATT)
      * ![1566532563231](D:\OneDrive\Pictures\Typora\1566532563231.png)
    * Dirty Page Table (DPT)
      * ![1566532572824](D:\OneDrive\Pictures\Typora\1566532572824.png)
    * `CHECKPOINT-BEGIN`: indicates start of checkpoint, `MasterRecord <- LSN_CB`
    * `CHECKPOINT_END`: contains ATT+DPT
  * Recovery phases
    * Analysis: Read the WAL to identify dirty pages in the buffer pool and active txns at the time of the crash
      * ![1566532854076](D:\OneDrive\Pictures\Typora\1566532854076.png)
      * ![1566532901365](D:\OneDrive\Pictures\Typora\1566532901365.png)
    * Redo: Repeat all actions starting from an appropriate point in the log
      * ![1566532928915](D:\OneDrive\Pictures\Typora\1566532928915.png)
      * ![1566532938765](D:\OneDrive\Pictures\Typora\1566532938765.png)
    * Undo: Reverse the actions of txns that did not commit before the crash
      * ![1566532951165](D:\OneDrive\Pictures\Typora\1566532951165.png)
    * ![1566532833596](D:\OneDrive\Pictures\Typora\1566532833596.png)
    * ![1566532971299](D:\OneDrive\Pictures\Typora\1566532971299.png)
    * performance
      * assume no crash in Redo, directly flush all changes to disks
      * lazily rollback changes in Undo, rewrite application to avoid long-running txns



## Distributed OLTP Databases

* communication cost :heavy_check_mark:
* System Architecture
  * ![1566549718028](D:\OneDrive\Pictures\Typora\1566549718028.png)
  * shared memory: CPUs have access to common memory address space via a fast interconnect
  * shared disk: All CPUs can access a single logical disk directly via an interconnect but each have their own private memories (execution layer :arrow_down: storage layer)
  * shared nothing: each DBMS instance has its own CPU, memory, disk (consistency is a problem)
* Design issues
  * Homogeneous Nodes: Every node in the cluster can perform the same set of tasks (albeit on potentially different partitions of data), provison/failover easy
  * Heterogeneous Nodes: Nodes are assigned specific tasks
  * ![1566549955934](D:\OneDrive\Pictures\Typora\1566549955934.png)
  * partitioning
    * naive: 1 table 1 node
    * horizontal: split table's tuples into disjoint subsets (physically or logically)
  * transactions coordination: distributed txn
    * centralized: middleware
    * decentralized 
* Atomic commit protocol: When a multi-node txn finishes, the DBMS needs to ask all of the nodes involved whether it is safe to commit
  * Two-Phase Commit
    * ![1566550187459](D:\OneDrive\Pictures\Typora\1566550187459.png)
    * optimizations
      * early prepare voting: If you send a query to a remote node that you know will be the last one you execute there, then that node will also return their vote for the  prepare phase with the query result
      * early acknowledgement after prepare: If all nodes vote to commit a txn, the coordinator can send the client an acknowledgement that their txn was successful before the commit phase finishes
    * coordinator crash -> participants decide
    * participant crash -> coordinate assume responded abort
  * Three-Phase Commit
  * Paxos: Consensus protocol where a coordinator proposes an outcome (e.g., commit or abort) and then the participants vote on whether that outcome should succeed.
    * Does not block if a majority of participants are available and has provably minimal message delays in the best case
    * ![1566550405622](D:\OneDrive\Pictures\Typora\1566550405622.png)
    * ![1566566738290](D:\OneDrive\Pictures\Typora\1566566738290.png)
    * ![1566566911136](D:\OneDrive\Pictures\Typora\1566566911136.png)
    * multi-paxos
      * ![1566566968668](D:\OneDrive\Pictures\Typora\1566566968668.png)
  * Raft
  * ZAB (Apache Zookeeper)
  * Viewstamped Replication
* Replication: The DBMS can replicate data across redundant nodes to increase availability
  * Replica configuration
    * Master-Replica
      * ![1566567027850](D:\OneDrive\Pictures\Typora\1566567027850.png)
    * Multi-master
      * ![1566567039239](D:\OneDrive\Pictures\Typora\1566567039239.png)
    * ![1566567054270](D:\OneDrive\Pictures\Typora\1566567054270.png)
  * K-safety: a threshold for determining the fault tolerance of the replicated database
    * K: # of replicas per data object that must exist at all times
  * Propagation scheme: When a txn commits on a replicated database, the DBMS has to decide whether it has to wait for that txn's changes to propagate to other nodes before it can send the acknowledgement to application
    * Synchronous: The master sends updates to replicas and then waits for them to acknowledge that they fully applied (i.e., logged) the changes
      * ![1566567305921](D:\OneDrive\Pictures\Typora\1566567305921.png)
    * Asynchronous: The master immediately returns the acknowledgement to the client without waiting for replicas to apply the changes
      * ![1566567334858](D:\OneDrive\Pictures\Typora\1566567334858.png)
    * Semi-Synchronous: Replicas immediately send acknowledgements without logging them
      * ![1566567382636](D:\OneDrive\Pictures\Typora\1566567382636.png)
    * integrity vs performance tradeoff
  * Propagation timing
    * continuous: The DBMS sends log messages immediately as it generates them (+commit/abort)
    * on commit: The DBMS only sends the log messages for a txn to the replicas once the txn is commits (no need for aborted log)
  * Active vs. Passive
    * Active-Active: A txn executes at each replica independently, need to check same results
    * Active-Passive: Each txn executes at a single location and propagates the changes to the replica
* CAP Theorem
  * ![1566567749839](D:\OneDrive\Pictures\Typora\1566567749839.png)
  * Consistency: If master says the txn committed, it should be immediately visible on replicas
  * Availability: Nodes respond requests
  * Partition Tolerance: Network partition
  * ![1566567947233](D:\OneDrive\Pictures\Typora\1566567947233.png)
* Federated Databases
  * different data models, query languages, limitations
  * no easy way to optimize queries
  * lots of data copying
  * Middleware, PostgreSQL Foreign Data Wrapper



## Distributed OLAP Databases

* Star Schema: single dimention layer around fact
  * ![1566568499576](D:\OneDrive\Pictures\Typora\1566568499576.png)
  * less storage space
  * better integrity & consistency
  * faster queries
* Snowflake Schema: multiple dimension layer across fact table
  * ![1566568518846](D:\OneDrive\Pictures\Typora\1566568518846.png)
  * less joins
* Execution Model
  * Push Query to Data: Send the query (or a portion of it) to the node that contains the data
    * perform as much filtering & processing as possible where data resides before transmitting over network
    * ![1566568777301](D:\OneDrive\Pictures\Typora\1566568777301.png)
  * Pull Data to Query: Bring the data to the node that is executing a query that needs it for processing
    * ![1566568817070](D:\OneDrive\Pictures\Typora\1566568817070.png)
* Fault Tolerance: take snapshots of intermediate results for a query during execution to recover
* Query Planning: consider location of data
  * Physical operators: Generate a single query plan and then break it up into partition-specific fragments
    * ![1566568950217](D:\OneDrive\Pictures\Typora\1566568950217.png)
  * SQL: Rewrite original query into partition-specific queries
  * Distributed Join Algorithm
    * One table is replicated at every node: Each node joins its local data and then sends their results to a coordinating node
    * Tables are partitioned on the join attribute: Each node performs the join on local data and then sends to a node for coalescing
    * Both tables are partitioned on different keys. If one of the tables is small: the DBMS broadcasts that table to all nodes
    * Both tables are not partitioned on the join key: The DBMS copies the tables by reshuffling them across nodes
      * ![1566569145175](D:\OneDrive\Pictures\Typora\1566569145175.png)
    * SEMI-JOIN: (R ⋉ S), same as projection pushdown
      * ![1566569351900](D:\OneDrive\Pictures\Typora\1566569351900.png)
* Cloud System: Database as a service (DBaaS)
  * Managed DBMS: No significant modification to the DBMS to be "aware" that it is running in a cloud environment
  * Cloud-Native DBMS: The system is designed explicitly to run in a cloud environment
    * Snowflake, Google BigQuery, Amazon Redshift, Microsoft SQL Azure
* Universal Formats
  * ![1566569438863](D:\OneDrive\Pictures\Typora\1566569438863.png)
* [VoltDB](https://15445.courses.cs.cmu.edu/fall2018/slides/25-voltdb.pdf)



## System Potpourri

* CockroachDB
  * ![1566569919123](D:\OneDrive\Pictures\Typora\1566569919123.png)
  * ![1566569924871](D:\OneDrive\Pictures\Typora\1566569924871.png)
  * ![1566569936135](D:\OneDrive\Pictures\Typora\1566569936135.png)
  * ![1566569951550](D:\OneDrive\Pictures\Typora\1566569951550.png)
* Google Spanner
  * ![1566569983100](D:\OneDrive\Pictures\Typora\1566569983100.png)
  * ![1566569999387](D:\OneDrive\Pictures\Typora\1566569999387.png)
  * ![1566570009041](D:\OneDrive\Pictures\Typora\1566570009041.png)
  * ![1566570021998](D:\OneDrive\Pictures\Typora\1566570021998.png)
  * ![1566570041403](D:\OneDrive\Pictures\Typora\1566570041403.png)
  * ![1566570052911](D:\OneDrive\Pictures\Typora\1566570052911.png)
  * ![1566570059359](D:\OneDrive\Pictures\Typora\1566570059359.png)
  * ![1566570079701](D:\OneDrive\Pictures\Typora\1566570079701.png)
  * ![1566570089516](D:\OneDrive\Pictures\Typora\1566570089516.png)
* mongoDB
  * ![1566570099656](D:\OneDrive\Pictures\Typora\1566570099656.png)
  * ![1566570123157](D:\OneDrive\Pictures\Typora\1566570123157.png)
  * ![1566570134136](D:\OneDrive\Pictures\Typora\1566570134136.png)
  * ![1566570144639](D:\OneDrive\Pictures\Typora\1566570144639.png)
  * ![1566570153422](D:\OneDrive\Pictures\Typora\1566570153422.png)
  * ![1566570164073](D:\OneDrive\Pictures\Typora\1566570164073.png)
  * ![1566570176394](D:\OneDrive\Pictures\Typora\1566570176394.png)

